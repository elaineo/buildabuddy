{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from semanticparser import *\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = 'franklin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/%s.txt' % username) as docs_file:\n",
    "    documents = docs_file.read().replace('\\n', '').decode('utf-8')\n",
    "\n",
    "# break into sentences\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "sents_all = sent_detector.tokenize(documents.strip())\n",
    "sent_generator = nltk.bigrams(sents_all)\n",
    "sents = [\" \".join(s) for s in sent_generator]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = remove_stopwords(sents, True)\n",
    "dictionary, lsi, index = texts_to_index(texts, 8, username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/%s.json' % username, 'w') as f:\n",
    "    json.dump(sents,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary.save('data/%s.dict' % username) \n",
    "lsi.save('data/%s-corpus.lsi' % username)\n",
    "index.save('data/%s-corpus.index' % username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### test functions\n",
    "def load_sents(username, root='data'):\n",
    "    \"\"\" Load documents\n",
    "            Preprocessed: dictionary, corpus, index, lsi\n",
    "            Archives: documents\n",
    "    \"\"\"\n",
    "    dictionary = corpora.Dictionary.load('%s/%s.dict' % (root,username))\n",
    "\n",
    "    with open('%s/%s.json' % (root,username)) as docs_file:\n",
    "        documents = json.load(docs_file)\n",
    "\n",
    "    lsi = models.LsiModel.load('%s/%s-corpus.lsi' % (root,username))\n",
    "    #index = similarities.MatrixSimilarity.load('data/%s-corpus.index' % username)\n",
    "    index = similarities.Similarity.load('%s/%s-corpus.index' % (root,username))\n",
    "\n",
    "    return documents, dictionary, lsi, index\n",
    "\n",
    "def test_response(username, t):\n",
    "    trash = [t]\n",
    "    documents0, dictionary0, lsi0, index0 = load_sents(username)\n",
    "    r = gen_response(documents0, dictionary0, lsi0, index0, t, trash, True)\n",
    "    print r\n",
    "\n",
    "def gen_response(sents, dictionary, lsi, index, t, trash, limit1=True):\n",
    "    # tokenize input sentence\n",
    "    clean_input = clean_str(t).lower().split()\n",
    "    \n",
    "    print clean_input\n",
    "\n",
    "    # get most similar post from input sentence\n",
    "    sims = query_page(clean_input, dictionary, lsi, index)\n",
    "\n",
    "    # repeat the process on the sentences in the doc\n",
    "    sample = [sents[sims[0][0]], sents[sims[1][0]], sents[sims[2][0]], sents[sims[3][0]],\n",
    "                sents[sims[4][0]], sents[sims[5][0]], sents[sims[6][0]], sents[sims[7][0]],\n",
    "                 sents[sims[8][0]],  sents[sims[9][0]],  sents[sims[10][0]],  sents[sims[11][0]],\n",
    "                  sents[sims[12][0]], sents[sims[13][0]],  sents[sims[14][0]],  sents[sims[15][0]]]\n",
    "\n",
    "    rmult = []\n",
    "    #reply = create_reply(sample, '')\n",
    "    if sample and sample not in trash:\n",
    "        # reply to the tweet\n",
    "        if limit1:\n",
    "            return sample\n",
    "        else:\n",
    "            rmult.append(sample)\n",
    "    if limit1:\n",
    "        return None\n",
    "    else:\n",
    "        return rmult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['do', 'you', 'have', 'any', 'good', 'drugs?']\n",
      "[u'\"But that the most acceptable service of God is doing good to man. \"That the soul is immortal.', u'good green tea. butter.', u'\"That he ought to be worshiped by adoration, prayer, and thanksgiving. \"But that the most acceptable service of God is doing good to man.', u'FRUGALITY. Make no expense but to do good to others or yourself;\\ri.e., waste nothing.', u'good\\r  1 lb. good green tea.', u\"Paying a due respect to God's ministers. These\\rmight be all good things; but, as they were not the kind of good things\\rthat I expected from that text, I despaired of ever meeting with them\\rfrom any other, was disgusted, and attended his preaching no more.\", u'To which I have besides some other inducements. Having emerged from the poverty and obscurity in which I was born and\\rbred, to a state of affluence and some degree of reputation in the\\rworld, and having gone so far through life with a considerable share of\\rfelicity, the conducing means I made use of, which with the blessing of\\rGod so well succeeded, my posterity may like to know, as they may find\\rsome of them suitable to their own situations, and therefore fit to be\\rimitated.', u'good bohea do. 2 doz.', u'O teach me what is good; teach me Thyself! Save me from folly, vanity, and vice,\\r          From every low pursuit; and fill my soul\\r          With knowledge, conscious peace, and virtue pure;\\r          Sacred, substantial, never-fading bliss!\"', u'Hereby, too, I shall indulge the inclination so natural in old men, to\\rbe talking of themselves and their own past actions; and I shall\\rindulge it without being tiresome to others, who, through respect to\\rage, might conceive themselves obliged to give me a hearing, since this\\rmay be read or not as any one pleases. And, lastly (I may as well\\rconfess it, since my denial of it will be believed by nobody), perhaps\\rI shall a good deal gratify my own vanity.', u\"5. Paying a due respect to God's ministers.\", u'Persons of good sense, I have since observed, seldom\\rfall into it, except lawyers, university men, and men of all sorts that\\rhave been bred at Edinborough. A question was once, somehow or other, started between Collins and me,\\rof the propriety of educating the female sex in learning, and their\\rabilities for study.', u':\\r\\r          \"Father of light and life, thou Good Supreme! O teach me what is good; teach me Thyself!', u'5. FRUGALITY.', u'Order, too, with regard to places for things, papers, etc.,\\rI found extreamly difficult to acquire. I had not been early\\raccustomed to it, and, having an exceeding good memory, I was not so\\rsensible of the inconvenience attending want of method.', u'Make no expense but to do good to others or yourself;\\ri.e., waste nothing. 6.']\n"
     ]
    }
   ],
   "source": [
    "test_response('franklin', \"do you have any good drugs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
